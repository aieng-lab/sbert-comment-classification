{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Analyze the results of the second experimentation stage (optimization of classification heads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZED_MODELS_PATH = \"../optimized_models\"\n",
    "\n",
    "MODEL_ALIASES = {\n",
    "    \"paraphrase-MiniLM-L3-v2\": \"pml3\",\n",
    "    \"all-mpnet-base-v2\": \"amb\",\n",
    "    \"all-MiniLM-L6-v2\": \"aml6\",\n",
    "    \"paraphrase-albert-small-v2\": \"pas\",\n",
    "    \"all-distilroberta-v1\": \"adr\",\n",
    "    \"baseline\": \"nlbse25\"\n",
    "}\n",
    "\n",
    "aliases = {v: k for k, v in MODEL_ALIASES.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for lang in [\"java\", \"python\", \"pharo\"]:\n",
    "    for folder_name in os.listdir(OPTIMIZED_MODELS_PATH):\n",
    "        file_path = os.path.join(OPTIMIZED_MODELS_PATH, folder_name, lang, \"results.json\")\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            try:\n",
    "                data = json.load(json_file)\n",
    "                data[\"language\"] = lang\n",
    "                data[\"experiment\"] = folder_name\n",
    "                results.append(data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from path {folder_name}/{lang}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df[\"model\"] = results_df[\"experiment\"].apply(lambda x: aliases[x.split(\"-\")[0]])\n",
    "results_df[\"iterations\"] = results_df[\"experiment\"].apply(lambda x: int(x.split(\"-\")[6].replace(\"i\", \"\")) if x != \"nlbse25\" else 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>hparams</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>avg_f1_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>avg_f1_test</th>\n",
       "      <th>avg_f1_test_diff</th>\n",
       "      <th>language</th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>default</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 0.9666666666666667, 0.9941690962099...</td>\n",
       "      <td>[1.0, 1.0, 0.9830508474576272, 0.9970760233918...</td>\n",
       "      <td>0.995447</td>\n",
       "      <td>[0.7542372881355932, 0.8536585365853658, 0.347...</td>\n",
       "      <td>[0.7355371900826446, 0.8203125, 0.390243902439...</td>\n",
       "      <td>[0.7447698744769874, 0.8366533864541833, 0.367...</td>\n",
       "      <td>0.638460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>python</td>\n",
       "      <td>aml6-sMO-bs32-e5-10-10-i40-hLR</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>default</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.8888888888888888, 1.0, 1.0, ...</td>\n",
       "      <td>[0.9719101123595506, 1.0, 0.9877551020408163, ...</td>\n",
       "      <td>[0.9857549857549858, 1.0, 0.9938398357289527, ...</td>\n",
       "      <td>0.897920</td>\n",
       "      <td>[0.6842105263157895, 0.9256198347107438, 0.666...</td>\n",
       "      <td>[0.6046511627906976, 0.9411764705882353, 0.730...</td>\n",
       "      <td>[0.6419753086419753, 0.9333333333333333, 0.697...</td>\n",
       "      <td>0.710518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pharo</td>\n",
       "      <td>amb-sMO-bs32-e5-10-10-i20-hLR</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm hparams                                    precision_train  \\\n",
       "16   default     NaN                          [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "35   default     NaN  [1.0, 1.0, 1.0, 0.8888888888888888, 1.0, 1.0, ...   \n",
       "\n",
       "                                         recall_train  \\\n",
       "16  [1.0, 1.0, 0.9666666666666667, 0.9941690962099...   \n",
       "35  [0.9719101123595506, 1.0, 0.9877551020408163, ...   \n",
       "\n",
       "                                             f1_train  avg_f1_train  \\\n",
       "16  [1.0, 1.0, 0.9830508474576272, 0.9970760233918...      0.995447   \n",
       "35  [0.9857549857549858, 1.0, 0.9938398357289527, ...      0.897920   \n",
       "\n",
       "                                       precision_test  \\\n",
       "16  [0.7542372881355932, 0.8536585365853658, 0.347...   \n",
       "35  [0.6842105263157895, 0.9256198347107438, 0.666...   \n",
       "\n",
       "                                          recall_test  \\\n",
       "16  [0.7355371900826446, 0.8203125, 0.390243902439...   \n",
       "35  [0.6046511627906976, 0.9411764705882353, 0.730...   \n",
       "\n",
       "                                              f1_test  avg_f1_test  \\\n",
       "16  [0.7447698744769874, 0.8366533864541833, 0.367...     0.638460   \n",
       "35  [0.6419753086419753, 0.9333333333333333, 0.697...     0.710518   \n",
       "\n",
       "    avg_f1_test_diff language                      experiment  \\\n",
       "16               0.0   python  aml6-sMO-bs32-e5-10-10-i40-hLR   \n",
       "35               0.0    pharo   amb-sMO-bs32-e5-10-10-i20-hLR   \n",
       "\n",
       "                model  iterations  \n",
       "16   all-MiniLM-L6-v2          40  \n",
       "35  all-mpnet-base-v2          20  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cases where the default head outperforms \n",
    "results_df.loc[results_df[\"hparams\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fff(row):\n",
    "    if row[\"algorithm\"] == \"default\":\n",
    "        return row[\"algorithm\"]\n",
    "\n",
    "    alg = row[\"algorithm\"].upper()\n",
    "    hparams = \", \".join([f\"{k}: {v}\" for k, v in row[\"hparams\"].items()])\n",
    "    return f\"{alg}, {hparams}\"\n",
    "\n",
    "results_df[\"head\"] = results_df.apply(fff, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"avg_precision_train\"] = results_df[\"precision_train\"].apply(lambda x: np.mean(x))\n",
    "results_df[\"avg_recall_train\"] = results_df[\"recall_train\"].apply(lambda x: np.mean(x))\n",
    "\n",
    "results_df[\"avg_precision_test\"] = results_df[\"precision_test\"].apply(lambda x: np.mean(x))\n",
    "results_df[\"avg_recall_test\"] = results_df[\"recall_test\"].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_821915/2134635617.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .groupby([\"language\", \"model\"], group_keys=False).apply(lambda x: x.nlargest(1, \"avg_f1_test\")) \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model</th>\n",
       "      <th>iterations</th>\n",
       "      <th>head</th>\n",
       "      <th>avg_precision_train</th>\n",
       "      <th>avg_recall_train</th>\n",
       "      <th>avg_f1_train</th>\n",
       "      <th>avg_precision_test</th>\n",
       "      <th>avg_recall_test</th>\n",
       "      <th>avg_f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>java</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>40</td>\n",
       "      <td>SVM, C: 0.01, kernel: rbf</td>\n",
       "      <td>0.998591</td>\n",
       "      <td>0.936907</td>\n",
       "      <td>0.965689</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.728891</td>\n",
       "      <td>0.740374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>java</td>\n",
       "      <td>all-distilroberta-v1</td>\n",
       "      <td>40</td>\n",
       "      <td>SVM, C: 0.1, kernel: linear</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.979642</td>\n",
       "      <td>0.988668</td>\n",
       "      <td>0.744317</td>\n",
       "      <td>0.741647</td>\n",
       "      <td>0.737756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>java</td>\n",
       "      <td>paraphrase-albert-small-v2</td>\n",
       "      <td>40</td>\n",
       "      <td>SVM, C: 0.01, kernel: rbf</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.947288</td>\n",
       "      <td>0.971390</td>\n",
       "      <td>0.764931</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.727682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>java</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>40</td>\n",
       "      <td>RF, max_depth: 9</td>\n",
       "      <td>0.998714</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>0.741029</td>\n",
       "      <td>0.731735</td>\n",
       "      <td>0.725131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>java</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>20</td>\n",
       "      <td>LR, C: 0.01</td>\n",
       "      <td>0.992213</td>\n",
       "      <td>0.952349</td>\n",
       "      <td>0.971424</td>\n",
       "      <td>0.731215</td>\n",
       "      <td>0.704005</td>\n",
       "      <td>0.711885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>java</td>\n",
       "      <td>baseline</td>\n",
       "      <td>20</td>\n",
       "      <td>SVM, C: 0.01, kernel: linear</td>\n",
       "      <td>0.993945</td>\n",
       "      <td>0.970561</td>\n",
       "      <td>0.981842</td>\n",
       "      <td>0.705819</td>\n",
       "      <td>0.720664</td>\n",
       "      <td>0.702185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pharo</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>20</td>\n",
       "      <td>default</td>\n",
       "      <td>0.974759</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.897920</td>\n",
       "      <td>0.811419</td>\n",
       "      <td>0.680544</td>\n",
       "      <td>0.710518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pharo</td>\n",
       "      <td>all-distilroberta-v1</td>\n",
       "      <td>20</td>\n",
       "      <td>RF, max_depth: 6</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>0.932890</td>\n",
       "      <td>0.954939</td>\n",
       "      <td>0.654909</td>\n",
       "      <td>0.687514</td>\n",
       "      <td>0.665834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pharo</td>\n",
       "      <td>paraphrase-albert-small-v2</td>\n",
       "      <td>60</td>\n",
       "      <td>SVM, C: 1.0, kernel: sigmoid</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>0.922105</td>\n",
       "      <td>0.672835</td>\n",
       "      <td>0.668640</td>\n",
       "      <td>0.657931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pharo</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>60</td>\n",
       "      <td>SVM, C: 1.0, kernel: poly</td>\n",
       "      <td>0.977625</td>\n",
       "      <td>0.848970</td>\n",
       "      <td>0.846151</td>\n",
       "      <td>0.688124</td>\n",
       "      <td>0.677517</td>\n",
       "      <td>0.641445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pharo</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>40</td>\n",
       "      <td>RF, max_depth: 6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942207</td>\n",
       "      <td>0.964299</td>\n",
       "      <td>0.626185</td>\n",
       "      <td>0.652919</td>\n",
       "      <td>0.636465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>pharo</td>\n",
       "      <td>baseline</td>\n",
       "      <td>20</td>\n",
       "      <td>RF, max_depth: 5</td>\n",
       "      <td>0.974476</td>\n",
       "      <td>0.824204</td>\n",
       "      <td>0.847203</td>\n",
       "      <td>0.721608</td>\n",
       "      <td>0.620435</td>\n",
       "      <td>0.635550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>python</td>\n",
       "      <td>all-distilroberta-v1</td>\n",
       "      <td>60</td>\n",
       "      <td>RF, max_depth: 6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671362</td>\n",
       "      <td>0.679691</td>\n",
       "      <td>0.673748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>python</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>20</td>\n",
       "      <td>RF, max_depth: 4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984393</td>\n",
       "      <td>0.992066</td>\n",
       "      <td>0.639991</td>\n",
       "      <td>0.682211</td>\n",
       "      <td>0.656355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>python</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>20</td>\n",
       "      <td>XG, max_depth: 2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637425</td>\n",
       "      <td>0.676542</td>\n",
       "      <td>0.654782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>python</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>60</td>\n",
       "      <td>LR, C: 0.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.653224</td>\n",
       "      <td>0.616481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>python</td>\n",
       "      <td>paraphrase-albert-small-v2</td>\n",
       "      <td>40</td>\n",
       "      <td>LR, C: 0.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995983</td>\n",
       "      <td>0.997981</td>\n",
       "      <td>0.620040</td>\n",
       "      <td>0.627290</td>\n",
       "      <td>0.615693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>python</td>\n",
       "      <td>baseline</td>\n",
       "      <td>20</td>\n",
       "      <td>LR, C: 0.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986617</td>\n",
       "      <td>0.993224</td>\n",
       "      <td>0.591914</td>\n",
       "      <td>0.632664</td>\n",
       "      <td>0.606248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language                       model  iterations  \\\n",
       "14     java           all-mpnet-base-v2          40   \n",
       "7      java        all-distilroberta-v1          40   \n",
       "1      java  paraphrase-albert-small-v2          40   \n",
       "0      java            all-MiniLM-L6-v2          40   \n",
       "8      java     paraphrase-MiniLM-L3-v2          20   \n",
       "15     java                    baseline          20   \n",
       "35    pharo           all-mpnet-base-v2          20   \n",
       "37    pharo        all-distilroberta-v1          20   \n",
       "44    pharo  paraphrase-albert-small-v2          60   \n",
       "41    pharo     paraphrase-MiniLM-L3-v2          60   \n",
       "32    pharo            all-MiniLM-L6-v2          40   \n",
       "47    pharo                    baseline          20   \n",
       "20   python        all-distilroberta-v1          60   \n",
       "29   python            all-MiniLM-L6-v2          20   \n",
       "19   python           all-mpnet-base-v2          20   \n",
       "25   python     paraphrase-MiniLM-L3-v2          60   \n",
       "17   python  paraphrase-albert-small-v2          40   \n",
       "31   python                    baseline          20   \n",
       "\n",
       "                            head  avg_precision_train  avg_recall_train  \\\n",
       "14     SVM, C: 0.01, kernel: rbf             0.998591          0.936907   \n",
       "7    SVM, C: 0.1, kernel: linear             0.998290          0.979642   \n",
       "1      SVM, C: 0.01, kernel: rbf             0.998958          0.947288   \n",
       "0               RF, max_depth: 9             0.998714          0.999960   \n",
       "8                    LR, C: 0.01             0.992213          0.952349   \n",
       "15  SVM, C: 0.01, kernel: linear             0.993945          0.970561   \n",
       "35                       default             0.974759          0.857955   \n",
       "37              RF, max_depth: 6             0.996337          0.932890   \n",
       "44  SVM, C: 1.0, kernel: sigmoid             1.000000          0.877304   \n",
       "41     SVM, C: 1.0, kernel: poly             0.977625          0.848970   \n",
       "32              RF, max_depth: 6             1.000000          0.942207   \n",
       "47              RF, max_depth: 5             0.974476          0.824204   \n",
       "20              RF, max_depth: 6             1.000000          1.000000   \n",
       "29              RF, max_depth: 4             1.000000          0.984393   \n",
       "19              XG, max_depth: 2             1.000000          1.000000   \n",
       "25                    LR, C: 0.1             1.000000          1.000000   \n",
       "17                   LR, C: 0.01             1.000000          0.995983   \n",
       "31                   LR, C: 0.01             1.000000          0.986617   \n",
       "\n",
       "    avg_f1_train  avg_precision_test  avg_recall_test  avg_f1_test  \n",
       "14      0.965689            0.764505         0.728891     0.740374  \n",
       "7       0.988668            0.744317         0.741647     0.737756  \n",
       "1       0.971390            0.764931         0.707527     0.727682  \n",
       "0       0.999336            0.741029         0.731735     0.725131  \n",
       "8       0.971424            0.731215         0.704005     0.711885  \n",
       "15      0.981842            0.705819         0.720664     0.702185  \n",
       "35      0.897920            0.811419         0.680544     0.710518  \n",
       "37      0.954939            0.654909         0.687514     0.665834  \n",
       "44      0.922105            0.672835         0.668640     0.657931  \n",
       "41      0.846151            0.688124         0.677517     0.641445  \n",
       "32      0.964299            0.626185         0.652919     0.636465  \n",
       "47      0.847203            0.721608         0.620435     0.635550  \n",
       "20      1.000000            0.671362         0.679691     0.673748  \n",
       "29      0.992066            0.639991         0.682211     0.656355  \n",
       "19      1.000000            0.637425         0.676542     0.654782  \n",
       "25      1.000000            0.588336         0.653224     0.616481  \n",
       "17      0.997981            0.620040         0.627290     0.615693  \n",
       "31      0.993224            0.591914         0.632664     0.606248  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[\"language\", \"model\", \"iterations\", \"head\", \"avg_precision_train\", \"avg_recall_train\", \"avg_f1_train\", \"avg_precision_test\", \"avg_recall_test\", \"avg_f1_test\"]] \\\n",
    "    .groupby([\"language\", \"model\"], group_keys=False).apply(lambda x: x.nlargest(1, \"avg_f1_test\")) \\\n",
    "    .sort_values(by=[\"language\", \"avg_f1_test\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlbse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
